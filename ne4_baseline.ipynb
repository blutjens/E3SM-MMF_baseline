{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f7e814-209a-41dd-b88b-f9e2567dd1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:13:34.211298: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    for kgpu in range(len(physical_devices)):\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[kgpu], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af7ceb6-c59c-4e09-a6bd-4cb822ca6f2d",
   "metadata": {},
   "source": [
    "# Build data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7d0ff-6444-4fe3-bb0e-e7f49e54e55c",
   "metadata": {},
   "source": [
    "## input and output variable list\n",
    "- Note that ptend_t and ptend_q0001 are not in the output (mlo) netcdf files, but calculated real-time on a tf Dataset object.\n",
    "- Variable list: https://docs.google.com/spreadsheets/d/1ljRfHq6QB36u0TuoxQXcV4_DSQUR0X4UimZ4QHR8f9M/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81c38be-c62a-400c-99e5-0a254dc4bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in/out variable lists\n",
    "vars_mli = ['state_t','state_q0001','state_ps','pbuf_SOLIN', 'pbuf_LHFLX', 'pbuf_SHFLX']\n",
    "vars_mlo = ['ptend_t','ptend_q0001','cam_out_NETSW','cam_out_FLWDS','cam_out_PRECSC','cam_out_PRECC','cam_out_SOLS','cam_out_SOLL','cam_out_SOLSD','cam_out_SOLLD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4732855b-ab01-4138-905b-c56c320b8e0f",
   "metadata": {},
   "source": [
    "## tf Dataset pipeline\n",
    "- ref: https://www.noahbrenowitz.com/post/loading_netcdfs/\n",
    "- ref: https://www.tensorflow.org/api_docs/python/tf/data/Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54137d82-57c4-46f6-bad4-b8aa2a8c9752",
   "metadata": {},
   "outputs": [],
   "source": [
    "mli_mean = xr.open_dataset('./norm_factors/mli_mean.nc')\n",
    "mli_min = xr.open_dataset('./norm_factors/mli_min.nc')\n",
    "mli_max = xr.open_dataset('./norm_factors/mli_max.nc')\n",
    "mlo_scale = xr.open_dataset('./norm_factors/mlo_scale.nc')\n",
    "\n",
    "def load_nc_dir_with_generator(filelist:list):\n",
    "    def gen():\n",
    "        for file in filelist:\n",
    "            \n",
    "            # read mli\n",
    "            ds = xr.open_dataset(file, engine='netcdf4')\n",
    "            ds = ds[vars_mli]\n",
    "            \n",
    "            # read mlo\n",
    "            dso = xr.open_dataset(file.replace('.mli.','.mlo.'), engine='netcdf4')\n",
    "            \n",
    "            # make mlo variales: ptend_t and ptend_q0001\n",
    "            dso['ptend_t'] = (dso['state_t'] - ds['state_t'])/1200 # T tendency [K/s]\n",
    "            dso['ptend_q0001'] = (dso['state_q0001'] - ds['state_q0001'])/1200 # Q tendency [kg/kg/s]\n",
    "            dso = dso[vars_mlo]\n",
    "            \n",
    "            # normalizatoin, scaling\n",
    "            ds = (ds-mli_mean)/(mli_max-mli_min)\n",
    "            dso = dso*mlo_scale\n",
    "\n",
    "            # stack\n",
    "            #ds = ds.stack({'batch':{'sample','ncol'}})\n",
    "            ds = ds.stack({'batch':{'ncol'}})\n",
    "            ds = ds.to_stacked_array(\"mlvar\", sample_dims=[\"batch\"], name='mli')\n",
    "            #dso = dso.stack({'batch':{'sample','ncol'}})\n",
    "            dso = dso.stack({'batch':{'ncol'}})\n",
    "            dso = dso.to_stacked_array(\"mlvar\", sample_dims=[\"batch\"], name='mlo')\n",
    "            \n",
    "            yield (ds.values, dso.values)\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_types=(tf.float64, tf.float64),\n",
    "        output_shapes=((None,124),(None,128))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff81df3-d60d-4b87-824b-da962936a1ea",
   "metadata": {},
   "source": [
    "## Instantiate tf.data.Dataset object here\n",
    "- Dataset file size and dimensions: https://docs.google.com/document/d/1HgfZZJM0SygjWvSAJ5kSfql9aXUFkvLybL36p-vmdZc/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a8551a-d5eb-40be-8d09-704f3e267d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Total # of input files: 360\n",
      "[TRAIN] Total # of columns (nfiles * ncols): 138240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:13:37.513746: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 16:13:39.550552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38250 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2023-05-10 16:13:39.552038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38250 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2023-05-10 16:13:39.553513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38250 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:82:00.0, compute capability: 8.0\n",
      "2023-05-10 16:13:39.555008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38250 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] Total # of input files: 360\n",
      "[VAL] Total # of columns (nfiles * ncols): 138240\n"
     ]
    }
   ],
   "source": [
    "shuffle_buffer=384*12\n",
    "\n",
    "# for training\n",
    "# First 5 days of each month for the first 6 years\n",
    "f_mli1 = glob.glob('/pscratch/sd/s/sungduk/hugging/E3SM-MMF_ne4/train/*/E3SM-MMF.mli.000[123456]-*-0[12345]-*.nc')\n",
    "f_mli2 = glob.glob('/pscratch/sd/s/sungduk/hugging/E3SM-MMF_ne4/train/*/E3SM-MMF.mli.0007-01-0[12345]-*.nc')\n",
    "f_mli = [*f_mli1, *f_mli2]\n",
    "f_mli = f_mli[0:72*5] # for debugging only\n",
    "random.shuffle(f_mli)\n",
    "print(f'[TRAIN] Total # of input files: {len(f_mli)}')\n",
    "print(f'[TRAIN] Total # of columns (nfiles * ncols): {len(f_mli)*384}')\n",
    "tds = load_nc_dir_with_generator(f_mli)\n",
    "tds = tds.unbatch()\n",
    "tds = tds.shuffle(buffer_size=shuffle_buffer, reshuffle_each_iteration=True)\n",
    "tds = tds.prefetch(buffer_size=4) # in realtion to the batch size\n",
    "\n",
    "# for validation\n",
    "# First 5 days of each month for the following 2 years\n",
    "f_mli1 = glob.glob('/pscratch/sd/s/sungduk/hugging/E3SM-MMF_ne4/train/*/E3SM-MMF.mli.0007-0[23456789]-0[12345]-*.nc')\n",
    "f_mli2 = glob.glob('/pscratch/sd/s/sungduk/hugging/E3SM-MMF_ne4/train/*/E3SM-MMF.mli.0007-1[012]-0[12345]-*.nc')\n",
    "f_mli3 = glob.glob('/pscratch/sd/s/sungduk/hugging/E3SM-MMF_ne4/train/*/E3SM-MMF.mli.000[89]-*-0[12345]-*.nc')\n",
    "f_mli_val = [*f_mli1, *f_mli2, *f_mli3]\n",
    "f_mli_val = f_mli_val[0:72*5] # for debugging only\n",
    "random.shuffle(f_mli_val)\n",
    "print(f'[VAL] Total # of input files: {len(f_mli_val)}')\n",
    "print(f'[VAL] Total # of columns (nfiles * ncols): {len(f_mli_val)*384}')\n",
    "tds_val = load_nc_dir_with_generator(f_mli_val)\n",
    "tds_val = tds_val.shuffle(buffer_size=shuffle_buffer, reshuffle_each_iteration=True)\n",
    "tds_val = tds_val.prefetch(buffer_size=4) # in realtion to the batch size\n",
    "\n",
    "#list(tds)\n",
    "# for count_batch in tds.repeat().batch(10).take(1):\n",
    "#     print(count_batch[0].numpy())\n",
    "#count_batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d7811-186e-4c54-a0c7-f8ac7d909211",
   "metadata": {},
   "source": [
    "# ML traning\n",
    "- While 4 GPUs are available on the node, using multi GPUs (with 'tf.distribute.MirroredStrategy()' strategy) does not speed up training process. It is possibly due to that the current Dataset pipeline is sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a060a60a-5cd7-41ed-8b8d-8b5d5fae4822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b596ead-cc85-46b4-a185-f88d15145377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Emulator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 124)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            500         ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            20          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          640         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 120)          15480       ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 8)            1032        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128)          0           ['dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,672\n",
      "Trainable params: 17,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# with strategy.scope():\n",
    "\n",
    "# model params\n",
    "input_length = 2*60 + 4\n",
    "output_length_lin  = 2*60\n",
    "output_length_relu = 8\n",
    "output_length = output_length_lin + output_length_relu\n",
    "n_nodes =4\n",
    "\n",
    "# constrcut a model\n",
    "input_layer    = keras.layers.Input(shape=(input_length,), name='input')\n",
    "hidden_0       = keras.layers.Dense(n_nodes, activation='relu')(input_layer)\n",
    "hidden_1       = keras.layers.Dense(n_nodes, activation='relu')(hidden_0)\n",
    "output_pre     = keras.layers.Dense(output_length, activation='elu')(hidden_1)\n",
    "output_lin     = keras.layers.Dense(output_length_lin,activation='linear')(output_pre)\n",
    "output_relu    = keras.layers.Dense(output_length_relu,activation='relu')(output_pre)\n",
    "output_layer   = keras.layers.Concatenate()([output_lin, output_relu])\n",
    "\n",
    "model = keras.Model(input_layer, output_layer, name='Emulator')\n",
    "model.summary()\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=keras.optimizers.Adam(), #optimizer=keras.optimizers.Adam(learning_rate=clr),\n",
    "              loss='mse',\n",
    "              metrics=['mse','mae','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff819836-1665-4e2e-970e-6413b040ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(tds, validation_data=tds_val, epochs=3)\n",
    "# to-do: add callbacks, and schedule lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82880fe1-e7e5-4e39-b264-433616729f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:13:42.358102: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-10 16:13:42.360609: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f0c0001d9b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-10 16:13:42.360625: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2023-05-10 16:13:42.360629: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2023-05-10 16:13:42.360632: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2023-05-10 16:13:42.360634: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2023-05-10 16:13:42.364991: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-10 16:13:42.386462: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:56] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.2\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-05-10 16:13:42.465102: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 47s 31ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0358 - accuracy: 0.9594 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0371 - val_accuracy: 0.9604\n",
      "Epoch: 2\n",
      "1440/1440 [==============================] - 45s 31ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0328 - accuracy: 0.9643 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0374 - val_accuracy: 0.9533\n",
      "Epoch: 3\n",
      "1440/1440 [==============================] - 44s 30ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0324 - accuracy: 0.9649 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0382 - val_accuracy: 0.9535\n"
     ]
    }
   ],
   "source": [
    "# Manually shuffling the order of input files.\n",
    "# \"tds = tds.shuffle(buffer_size=<global>, reshuffle_each_iteration=True)\" is possible,\n",
    "# however, it is slow.\n",
    "# So employing global shuffle (by file names) + local shuffle (using .shuffle).\n",
    "\n",
    "N_EPOCHS = 3\n",
    "shuffle_buffer = 12*384 #ncol=384\n",
    "batch_size= 96 # 384/4\n",
    "\n",
    "n=0\n",
    "while n < N_EPOCHS:\n",
    "    random.shuffle(f_mli)\n",
    "    tds = load_nc_dir_with_generator(f_mli) # global shuffle by file names\n",
    "    tds = tds.unbatch()\n",
    "    tds = tds.shuffle(buffer_size=shuffle_buffer, reshuffle_each_iteration=False) # local shuffle by elements\n",
    "    tds = tds.batch(batch_size)\n",
    "    tds = tds.prefetch(buffer_size=int(shuffle_buffer/384)) # in realtion to the batch size\n",
    "\n",
    "    random.shuffle(f_mli_val)\n",
    "    tds_val = load_nc_dir_with_generator(f_mli_val)\n",
    "    tds_val = tds_val.unbatch()\n",
    "    tds_val = tds_val.shuffle(buffer_size=shuffle_buffer, reshuffle_each_iteration=False)\n",
    "    tds_val = tds_val.batch(batch_size)\n",
    "    tds_val = tds_val.prefetch(buffer_size=int(shuffle_buffer/384))\n",
    "\n",
    "\n",
    "    \n",
    "    print(f'Epoch: {n+1}')\n",
    "    model.fit(tds, validation_data=tds_val)\n",
    "    \n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0324ca8-4eca-4890-80bc-4ee91dc12168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-tf_conda",
   "language": "python",
   "name": "myenv-tf_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
